% Template for ICASSP-2018 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,amssymb,graphicx,bm,algorithm,algpseudocode,mathtools,xcolor,siunitx}
\graphicspath{{figures/}}

% \newcommand{\R}{\mathbb{R}}
% \renewcommand{\vec}[1]{\ensuremath{\mathbf{#1}}}
% \providecommand{\mat}[1]{\ensuremath{\mathbf{#1}}}
% \providecommand{\vx}{\vec{x}}
% \providecommand{\vy}{\vec{y}}
% \providecommand{\ve}{\vec{e}}
% \providecommand{\vn}{\vec{n}}
% \providecommand{\vA}{\vec{A}}
\providecommand{\norm}[1]{\left\lVert#1\right\rVert}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\title{Optimal Measurement Configuration in Computational \\ Diffractive Imaging}

\name{Evan Widloski \qquad Ulas Kamaci \qquad Farzad Kamalabadi}
\address{
Department of Electrical and Computer Engineering and Coordinated Science Laboratory, \\
University of Illinois at Urbana-Champaign, Urbana, IL 61801, USA
}

\begin{document}
\maketitle

\begin{abstract}
% Spectral imaging, forming images of a scene at many wavelengths, is a
% fundamental analysis technique with many scientific applications. Diffractive
% lenses can achieve very high resolution in x-ray and UV regimes as compared to
% reflective and refractive optics. Their wavelength dependent focal length
% enables them to be used in spectral imaging of polychromatic sources, where the
% focused image of each spectral component is formed at different distances from
% the diffractive lens. If measurements are taken at each of these focus
% locations, it is possible to computationally reconstruct the spectral scene by
% solving an inverse problem. In this paper, we propose a greedy algorithm for
% finding a measurement configuration which results in better reconstructions than
% a conventional configuration selection strategy.
% In this paper, we investigate the problem of data acquisition in a multispectral
% diffractive imaging system.  Diffractive systems have the property that the
% spectral components of a polychromatic source are focused at different distances
% from the lens.  This means that in order to image a source at more than one
% wavelength, multiple measurements must be made with a moving detector. However,
% the choice of where to make these measurements is non-obvious and has
% implications on the quality of the reconstructions. Furthermore, an exhaustive
% search of all possible measurement configurations grows exponentially with the
% number of sources and is computationally infeasible. We propose a greedy
% backward elimination algorithm for finding acquisition locations and show that
% reconstruction quality is improved over a naive acquisition strategy.

Diffractive lenses have recently been applied to the domain of multispectral
imaging in the x-ray and UV regimes, where they can achieve very high resolution
as compared to reflective and refractive optics. By taking measurements at
different focal lengths it is possible to reconstruct individual spectral
components of a polychromatic source. However, the problem of where to take
measurements is non-obvious. In this work, we apply the sequential backward selection
algorithm to suboptimally search for a configuration which minimizes expected
reconstruction error. By approximating the forward system as a circular
convolution and making assumptions on the source and noise, we greatly reduce the complexity of evaluating this cost.

\end{abstract}

\begin{keywords}
Spectral imaging, diffractive optics, measurement configuration, sequential
backward selection, subset selection
\end{keywords}

\section{Introduction}
\label{sec:intro}
Spectral imaging is the formation of images at different wavelengths in the
electromagnetic spectrum.  With images usually taken in the visible, x-ray,
ultraviolet (UV), or infrared bands (IR), it has applications in medicine,
geographic surveying, astronomy, and solar physics \cite{shaw2003spectral},
\cite{garini2006spectral}. A common method to perform spectral imaging is to use
a set of optical filters to selectively pass light of specific wavelengths of
interest.

% Spectral imaging is forming images of a scene as a function of wavelength, is a
% fundamental diagnostic technique in various fields such as astronomy,
% surveillance, agriculture and medicine \cite{shaw2003spectral},
% \cite{garini2006spectral}. Forming a three dimensional (3D) data-cube (one
% wavelength and two spatial dimensions) with two dimensional (2D) detector
% measurements can be done by taking multiple exposures. To capture the spectrum
% of a scene, conventional spectral imagers combine regular camera optics with
% either additional wavelength filters or dispersive elements (e.g diffraction
% grating).


An alternative approach is to use a diffractive lens to perform spectral imaging
\cite{oktem2014icip}. Diffractive lenses are often preferred in the UV or x-ray
regimes over reflective optics because manufacturing tolerances at these
wavelengths must be much tighter than in the visible regime in order to get a
similar resolution performance \cite{davila2011high}. Since diffractive optics can
be manufactured using a photolithographic process, they can be produced at a
higher precision compared to the grinding process used to produce conventional
reflective optics. Similarly, refractive optics are unsuitable for UV or x-ray
imaging because glass is opaque at these wavelengths. Figures
\ref{fig:diff_lens}(b) and \ref{fig:diff_lens}(c) are two examples of a pattern
that can be etched into silicon wafer to produce a diffractive lens.

\begin{figure}[htb]

\begin{minipage}[b]{0.48\linewidth}
  \centering
  \centerline{\includegraphics[width=4.0cm]{diffraction_ps_rgb}}
  \centerline{(a)}\medskip
\end{minipage}
\hfill
\begin{minipage}[b]{0.24\linewidth}
  \centering
  \centerline{\includegraphics[width=2.0cm]{zoneplate}}
  \centerline{(b)}\medskip
\end{minipage}
\hfill
\begin{minipage}[b]{0.24\linewidth}
  \centering
  \centerline{\includegraphics[width=2.0cm]{photonsieve}}
%  \vspace{1.5cm}
  \centerline{(c)}\medskip
\end{minipage}
\caption{(a) diffraction of a polychromatic wave through a diffractive lens (b) Fresnel zone
plate (c) photon sieve}
\label{fig:diff_lens}
%
\end{figure}

% FIXME
Diffractive lenses have the property that each wavelength comes to focus at
different distances from the lens (see Figure \ref{fig:diff_lens}(a)
\cite{attwood2017x}. In fact, any plane consists of a sum of all spectral
components of the source at varying degrees of focus, which depends on the
distance from lens and the wavelenght. Then a strategy to perform spectral
imaging is to take a measurement at each focal plane and solve an inverse
problem consisting of disentangling and deblurring of measurements in order to
recover the original spectral components \cite{oktem2014icip}. Considering the
fact that each measurement will contain noise, deblurring problem will be ill
posed. Furthermore, the inverse problem becomes more ill posed if the wavelengths
of interest are very close to each other, because it gets harder to disentangle.

In an ill posed problem like this, the choice of measurement planes becomes very
crucial and has direct impact on the reconstruction quality. Although taking
many measurements, or choosing longer exposure time will make the problem more
well posed, practical applications usually impose limits on the total
measurement time due to the dynamics of the scene. Even if there is no time
limitation, given the freedom to take $M$ measurements out of $C$ candidate
plane locations, it is desired to find the best configuration that maximizes the
reconstruction quality.

Traditionally, measurement locations are selected at the plane of focus for each
spectral component. However, as we show later in this paper, it is possible to
improve on the reconstruction quality in some situations by choosing a different
configuration. In this paper, we propose a greedy backward selection algorithm
for automatically discovering such a measurement configuration given a set of
candidate plane locations. Exploiting the structures of the imaging model, we
have implemented the algorithm efficiently, which otherwise would be infeasible
to implement.

In the next section we mathematically model the diffractive imaging system and
formulate the inverse problem of recovering spectral components. We go on to
show the measurement selection algorithm in Section 3. Fast implementation of
this algorithm is presented in Section 4. Next, the complexity of the fast
implementation is analysed and compared with a naive implementation. The last
section is dedicated to the numerical results that demonstrate the usefulness of
the algorithm.

% A different approach is to use a diffractive lens to perform spectral imaging.
% Diffractive lenses focus light using the diffraction principle. They have
% wavelength dependent focal length which is the property that enables them to be
% used as spectral imagers (see Figure \ref{fig:diff_lens}). Examples of
% diffractive lenses are Fresnel zone plates and their modifications (e.g. photon
% sieve) (see Figure \ref{fig:diff_lens}). Diffractive lenses are preferred in
% applications in UV and x-ray regimes where they can provide high resolution
% whereas reflective optics are very costly to manufacture to achieve high
% resolution and refractive lenses cannot be used due to light absorption in these
% regimes.


% Photon sieve spectral imaging (PSSI) is a modality that takes the advantage of
% the wavelength dependent focal length of a photon sieve to perform high
% resolution spectral imaging \cite{oktem2014icip}. It takes multiple exposures of
% the scene at different distances from the lens. Figure \ref{fig:pssi_drawing}
% illustrates the PSSI measurements for a scene radiating at two wavelengths
% $\lambda_1$ and $\lambda_2$. Each measurement consists of blurred superposition
% of the spectral images. The spectral images are then reconstructed from these
% measurements by solving a multi-frame deconvolution problem.


\begin{figure}[htb]
  \begin{minipage}[b]{1\linewidth}
    \centering
    \centerline{\includegraphics[width=8.5cm]{diffraction_system}}
  \end{minipage}
  \caption{Imaging a scene with emissions at wavelengths $\lambda_1$ and
  $\lambda_2$. Measurements $y_1$ and $y_2$ are taken at two positions where one wavelength
  is in focus and the other is out of focus.}
  \label{fig:pssi_drawing}
\end{figure}

% Choice of measurement planes is an important factor affecting the reconstruction
% quality of the spectral images. Where to take measurements to maximize the
% fidelity of the reconstructions?

% One way is to scan the
% wavelength dimension by using color filters with narrow bandpass to filter
% desired wavelengths at each exposure. Another way is to capture the whole
% spectrum of a portion of the scene at an exposure, and scan a spatial dimension.
% In both methods, the 3D data-cube is then simply reconstructed by stacking the
% 2D measurements in the scanning dimension.

% There are also computational methods which rely on signal processing methods and
% computational power to improve upon the conventional methods in terms of spatial
% and spectral resolutions, total exposure time etc. They utilize more
% sophisticated image acquisition techniques than the conventional scanning-based
% methods, and computationally reconstruct the data-cube from multiplexed/encoded
% measurements. Such methods include compressive coded aperture snapshot spectral
% imaging (CASSI) [REF], compressive hyperspectral imaging by separable spectral
% and spatial operators (CHISS) [REF], and photon sieve spectral imaging (PSSI)
% \cite{oktem2014icip}.

% We will use PSSI as an example modality to explain and demonstrate our work
% because it  uses a diffractive lens, and it is a computational spectral imaging
% modality \cite{oktem2014icip}. Photon sieves, just like Fresnel zone plates, are
% diffractive lenses that use diffraction phenomenon to focus light. Diffractive
% lenses are preferred in applications in UV and x-ray regimes since they can
% provide high resolution whereas reflective optics are very costly to manufacture
% to achieve high resolution and refractive lenses cannot be used due to light
% absorption. They have wavelength dependent focal length which is what behind the
% working principle of PSSI. It takes multiple exposures at different distances
% from the lens to sample the measurement space.

\section{Forward Model and Statistical Formulation}
\label{sec:format}
In this section, we mathematically model a diffractive imaging
system and describe the process of recovering the spectral components. Consider
a polychromatic source that has $S$ two-dimensional spectral components
$\bm{x}_1, \dots, \bm{x}_S$. Using a moving detector, we make $M$
two-dimensional measurements $\bm{y}_1, \dots, \bm{y}_M$ at distances $d_1,
\dots, d_M$ from the lens. We allow for repeated measurements at the same plane
for a more flexible model that can take into account non equal exposure times.
% FIXME
Due to linearity, each measurement is a superposition of blurred versions
of the $S$ sources. More formally,

\begin{equation}
\bm{y}_m = \sum_{s=1}^S \bm{a}_{m,s} \ast \bm{x}_s + \bm{n}_s
\label{eq:fwd_model}
\end{equation}

where $\bm{a}_{m,s}$ is a blurring kernel known as a \emph{point spread
function} (PSF) and $\ast$ is a 2D convolution. Each PSF depends on the
associated source wavelength and measurement location and can be computed
analytically.
% An example set of PSF images for $M=S=2$ case is given in Figure \ref{fig:psfs}.

Since convolution is a linear operation, we can rewrite the above equation as a
linear system

\begin{equation}
  \underbrace{
    \begin{bmatrix}\bm{y}_1 \\ \vdots \\ \bm{y}_M\end{bmatrix}
  }_{\bm{y}}
  =
  \underbrace{
    \begin{bmatrix}
      \bm{A}_{1, 1} & \hdots & \bm{A}_{1, S} \\
      \vdots & & \vdots \\
      \bm{A}_{M, 1} & \hdots & \bm{A}_{M, S}
    \end{bmatrix}
  }_{\bm{A}_{\bm{d}}}
  \underbrace{
    \begin{bmatrix}\bm{x}_1 \\ \vdots \\ \bm{x}_S\end{bmatrix}
  }_{\bm{x}}
  +
  \underbrace{
    \begin{bmatrix}\bm{n}_1 \\ \vdots \\ \bm{n}_M\end{bmatrix}
  }_{\bm{n}}
\label{eq:fourier_mtx}
\end{equation}

% \begin{figure}[htb]
%   \begin{minipage}[b]{1\linewidth}
%     \centering
%     \centerline{\includegraphics[width=5cm]{psfs}}
%   \end{minipage}
%   \caption{Example point spread functions for measuring a source with 2 spectral
%     components at the focal planes of each component.}
%   \label{fig:psfs}
% \end{figure}

where $\bm{y}_m$, $\bm{x}_s$ and $\bm{n}_m$ have been flattened from their
original 2D shape, and each $\bm{A}_{m,s}$ is a block-toeplitz
matrix with toeplitz blocks formed from 2D convolution with PSF $\bm{a}_{m,s}$.
We will refer to the matrix containing all $\bm{A}_{m,s}$
generated by measurements taken at $\bm{d} = \{d_1, \dots, d_M\}$ as
$\bm{A}_{\bm{d}}$.

The problem of where to take measurements $\bm{y}_1, \dots, \bm{y}_M$ has not
been addressed and affects the reconstruction quality.  In order to
compare the impact of different measurement configurations on the reconstruction, it is
necessary to define some cost for the measurement matrix $\bm{A}_{\bm{d}}$.  A common cost
metric is the expected reconstruction error, or expected sum of squared errors
(SSE). However, we must have some strategy for the recovery of $\bm{x}$ to get
reconstruction error and we must make statistical assumptions about $\bm{x}$.
Maximum a posteriori (MAP) estimation is one such strategy.

We assume the original spectral components and noise are distributed according to a
normal distribution such that $\bm{x} \sim \mathcal{N}(\bm{\mu}_{\bm{x}}, \bm{\Sigma}_{\bm{x}})$ and
$\bm{n} \sim \mathcal{N}(0, \bm{\Sigma}_{\bm{n}})$.  The MAP estimate is then

% FIXME - dimensionality -> n
% use A instead of H?
$$
\begin{aligned}
  \bm{x}_{MAP} &= \arg \max_{\bm{x} \in \mathbb{C}^n} p(\bm{x} | \bm{y})
  = \arg \max_{\bm{x}} p(\bm{y}|\bm{x}) p(\bm{x})\\
  &= \arg \min_{\bm{x}} \left[  - \log(p(\bm{y}|\bm{x})) - \log
  p(\bm{x})\right] \\
  &= \bm{x}_0 + \left( \bm{A}_{\bm{d}}^H\bm{\Sigma}_{\bm{n}}^{-1} \bm{A}_{\bm{d}} +
    \bm{\Sigma}_{\bm{x}}^{-1}\right)^{-1}
  \cdot  \bm{A}_{\bm{d}}^H \bm{\Sigma}_{\bm{n}}^{-1} (\bm{y} - \bm{A}_{\bm{d}} \bm{\mu}_{\bm{x}})
\end{aligned}
$$
The reconstruction error is defined as $\bm{e} = \bm{x} - \bm{x_{\text{MAP}}}$,
and the expected sum of squared error cost is $E[\norm{\bm{e}}_2^2]$. This
expression can be rewritten in terms of the error covariance:

\begin{align*}
E[\norm{\bm{e}}_2^2] =  E[\bm{e}^H\bm{e}] & = E[tr(\bm{e}^H\bm{e})] = E[tr(\bm{e}\bm{e}^H)] \\
& = tr(E[\bm{e}\bm{e}^H]) = tr(\bm{\Sigma}_{\bm{e}})
\end{align*}

where the error covariance matrix is defined as $\bm{\Sigma}_{\bm{e}} =
E[\bm{e}\bm{e}^H]$ and has the closed form expression:
\begin{equation}
\bm{\Sigma}_{\bm{e}} = \left( \bm{A}_{\bm{d}}^H\bm{\Sigma}_{\bm{n}}^{-1} \bm{A}_{\bm{d}} +
    \bm{\Sigma}_{\bm{x}}^{-1}\right)^{-1}
\end{equation}

Combining the above equations, we can now write a cost metric which lets us evalute
the expected reconstruction error for a particular measurement configuration $\bm{d}$:
\begin{equation}
\text{Cost}(\bm{d}) = E[\norm{\bm{e}}_2^2] = tr\left(\left( \bm{A}_{\bm{d}}^H\bm{\Sigma}_{\bm{n}}^{-1} \bm{A}_{\bm{d}} +
    \bm{\Sigma}_{\bm{x}}^{-1}\right)^{-1}\right)
\end{equation}

% In this section, we mathematically model a multispectral diffractive imaging system.
% Consider a polychromatic source that has spectral emissions at $S$ distinct
% wavelengths $\lambda_1, \dots, \lambda_S$. Using a moving detector,
% we take measurements at $M$ different measurement planes, with distances from the
% sieve $d_1, \dots, d_M$ (see Figure \ref{fig:meas}).  Each of these $M$
% measurements is a sum over the $S$ sources, with each source blurred to varying
% degrees.

% With this,
% the discrete model that relates the noiseless measurements to the sources is
% given by the following model:
% \begin{equation}
% y_k[m,n] = \sum_{p=1}^P h_{d_k,\lambda_p}[m,n] \ast x_p[m,n] \ , \ k = 1,2,\dots, K
% \label{eq:fwd}
% \end{equation}
% where $m,n=-N/2, \dots, N/2-1$ assuming that the detector has $N\times N$
% pixels. Here, $x_p$ denotes the discretized intensity of the source with
% wavelength $\lambda_p$, and $h_{d_k,\lambda_p}$ denotes the discretized point
% spread function (PSF) of the photon sieve for the wavelength $\lambda_p$ and
% plane distance $d_k$, which has a closed form expression given in
% \cite{oktem2013icip}. So, each measurement $y_k$ is a superposition of all the
% sources $x_p$ convolved with their corresponding PSFs $h_{d_k,\lambda_p}$.

% \begin{figure}[h]
% \includegraphics[width=0.45\textwidth]{poster1}
% \caption{PSSI measurement configuration.}
% \label{fig:meas}
% \end{figure}


% Since \eqref{eq:fwd} is a linear relation between the sources and the
% measurements, we can represent it using matrix-vector form which will be useful
% in formulating the inverse problem. Denote by $\vx_p$ and $\vy_k$ the vectorized
% versions of $x_p[m,n]$ and $y_k[m,n]$. Then, we have
% \begin{equation}
% \vy = \vec A \vx + \vec w
% \label{eq:mtx-vec}
% \end{equation}
% with
% \begin{equation}
% \vy = \begin{bmatrix}
% \vy_1 \\ \vdots \\ \vy_K
% \end{bmatrix}, \vA = \begin{bmatrix}
% \vA_{11} \hspace{-.1 in}& \dots \hspace{-.1 in}& \vA_{1P} \\
% \vdots \hspace{-.1 in}& \ddots \hspace{-.1 in}& \vdots \\
% \vA_{K1} \hspace{-.1 in}& \dots \hspace{-.1 in}& \vA_{KP}
% \end{bmatrix}, \vx = \begin{bmatrix}
% \vx_1 \\ \vdots \\ \vx_P
% \end{bmatrix}, \vw = \begin{bmatrix}
% \vw_1 \\ \vdots \\ \vw_K
% \end{bmatrix}
% \end{equation}

% where $\vw_k \in \R^{N^2}$ is additive Gaussian noise vector with $(\vw_k)_i
% \sim \mathcal N (0, \sigma_k^2)$; and $\vA_{k,p} \in \R^{N^2 \times N^2}$ is the
% convolution matrix corresponding to the PSF $h_{d_k,\lambda_p}$. We assume that
% the periodic boundary conditions hold, which makes the matrices $\vA_{k,p}$
% block circulant with circulant blocks (BCCB). This allows computationally
% efficient algorithms in the image reconstruction.


\section{Measurement Selection Algorithm}

With a method of evaluating the effect a particular configuration $\bm{d}$ has
on reconstruction error, we can begin considering which configurations are best
suited for minimizing error.  For example, if we are provided with a set of $C$
candidate measurement locations, we may wish to find a subset of size $M$ which
minimizes reconstruction error. This is known as a \emph{subset selection} problem.
One might think to simply  search over all possible measurement configurations
of size $M$, but this exhaustive search requires $\binom{C}{M}$ evalutions of
cost, growing on the order of $O(C^M)$.
% With a method of comparing the *** of two measurement configurations, one might
% think to simply search all possible measurements and choose the best.  However,
% the computational cost of an exhaustive search grows too quickly and is
% infeasible for most realistic scenarios.  For example, consider a scenario in
% which there are $C$ candidate measurement locations of which we would like to
% select a subset of size $M$ to form our measurement matrix $\bm{A}$.
% Exhaustively searching through all possible configurations of $\bm{A}$ would
% require $\binom{C}{M}$ iterations, recomputing $\text{Cost}(\bm{A})$ each time.

An alternative method which is more computationally feasible is known as
\emph{greedy hill climbing}, or more specifically, \emph{sequential backward
selection} (SBS) \cite{sharif}. In SBS, one measurement location is eliminated from $\bm{d}$ in each
iteration until only $M$ locations remain. As reconstruction error generally
increases as the number of measurements dereases, SBS selects for elimination the
measurement that incurs the smallest increase in cost in each iteration.

\begin{algorithm}
  \begin{algorithmic}
    \caption{SBS Algorithm}
    \State $\bm{d} = \{d_1, \dots, d_C\}$
    \Repeat
      \State $d' = \arg \min_{d \in \bm{d}} \text{Cost}(\bm{d} \backslash d))$
      \State $\bm{d} = \bm{d} \backslash d'$
    \Until{$|\bm{d}| = M$}
  \end{algorithmic}
\end{algorithm}

Unlike an exhaustive search, the complexity of SBS is not combinatorial.  As the
size of $\bm{d}$ shrinks with each iteration, the number of cost evaluations for each
minimization step decreases.  The total number of cost evaluations is

$$
\begin{aligned}
  \sum_{|\bm{d}| = M}^C |\bm{d}|
  &= \frac{C
    (C + 1)}{2} - \frac{M(M + 1)}{2} \\
  &= O(C^2 - M^2)
\end{aligned}
$$

% Having defined the cost metric, we are now looking for the best measurement
% configuration to minimize the cost. Suppose we take $M$ measurements, each at
% a distance $d_m$ from the lens for $m = 1, \dots, M$.

% \begin{equation}
% \hat {\bm A} = \argmin_{\vA \in Q} \ \text{Cost}(\bm{A})
% \label{eq:inverse}
% \end{equation}
% The goal in the inverse problem is to reconstruct the spectral components
% $\bm{x}_1, \dots, \bm{x}_S$ from the noisy, blurry and superimposed measurements
% $\bm{y}_1, \dots, \bm{y}_M$. This is known as a \emph{multi-frame deconvolution
% problem} with multiple sources.  However, deconvolution is known to be highly
% ill-posed, which means that direct inversion of the matrix containing the PSFs
% (or its least square approximation) amplifies the noise in the measurements and
% leads to poor reconstructions. To avoid noise amplification, the problem needs
% to be regularized. The inverse problem can then be formulated as a regularized
% optimization problem as follows:
% \begin{equation}
% \hat \vx = \argmin_{\vx} \norm{\vA\vx-\vy}_2^2 + \lambda \mathcal R(\vx)
% \label{eq:inverse}
% \end{equation}
% where the first term ensures that the reconstructions comply with the
% measurements and the second term is the regularization term with parameter
% $\lambda>0$. In this paper, we are interested in

\section{Fast Implementation}
While the SSE cost applies to any general linear system, we can augment the
complexity reduction achieved by SBS by making assumptions about the structure
of $\bm{A}_{\bm{d}}$, $\bm{\Sigma}_{\bm{n}}$ and $\bm{\Sigma}_{\bm{x}}$.
Specifically, if we assume the blocks of these matrices are block-circulant with
circulant blocks (BCCB), then they can be diagonalized by the 2D DFT matrix
where operations involving multiplications and inversions are much faster.

For $\bm{A}_{\bm{d}}$ this means that each block $\bm A_{m,s}$ is BCCB and
corresponds to circular convolution with the kernel $\bm a_{m,s}$. For $\bm
\Sigma_n$, we assume that the noise is uncorrelated among the pixels and
measurement planes with variance $(1/\lambda)$, so $\bm \Sigma_n=(1/\lambda) \bm
I$ where $\bm I$ represents the identity matrix. For $\bm \Sigma_x$, each of its
blocks being BCCB means that the covariance among image pixels are represented
by 2D convolution kernels.

Assuming $N \times N$ images, each $N^2 \times N^2$ block $\bm A_{m,s}$ of $\bm
{A_d}$ can be decomposed as $\bm A_{m,s} = \bm F^{-1} \widetilde{\bm A}_{m,s}
\bm F$ where $\widetilde{\bm A}_{m,s}$ is the diagonal matrix consisting of the
2D DFT of $\bm a_{m,s}$. This yields
\vspace{-0.1 in}
\begin{equation}
  \bm {A_d}=
  \underbrace{
    \begin{bmatrix}
      \bm F^{-1} \hspace{-0.2 in}& \hspace{-0.2 in} & \hspace{-0.20 in} \vspace{-0.1 in}\text{\Large 0} \\
        \vspace{-0.05 in}&\hspace{-0.20 in} \ddots &  \\
      \text{\Large 0} \hspace{-0.17 in}& \hspace{-0.2 in} & \hspace{-0.15 in} \bm F^{-1}
    \end{bmatrix}
  }_{\widetilde{\bm F}^{-1}}
  \underbrace{
    \begin{bmatrix}
      \widetilde{\bm A}_{1,1} \hspace{-0.1 in}&\hspace{-0.1 in} \hdots & \hspace{-0.1 in} \widetilde{\bm A}_{1,S} \vspace{-0.02 in}\\
      \vspace{-0.02 in}\vdots &\hspace{-0.1 in} \ddots& \vdots \\
      \widetilde{\bm A}_{M,1} \hspace{-0.1 in}&\hspace{-0.1 in} \hdots & \hspace{-0.1 in} \widetilde{\bm A}_{M,S} \\
    \end{bmatrix}
  }_{\widetilde{\bm A}_{\bm d}}
  \underbrace{
    \begin{bmatrix}
      \bm F \hspace{-0.1 in}& & \hspace{-0.18 in} \vspace{-0.1 in}\text{\Large 0} \\
        \vspace{-0.05 in}& \hspace{-0.12 in}\ddots &  \\
  \hspace{0.05 in} \text{\Large 0} & & \hspace{-0.12 in} \bm F
    \end{bmatrix}
  }_{\widetilde{\bm F}}
\label{eq:fourier_mtx}
\end{equation}
\vspace{-0.1 in}

so, we have $\bm{A_d} = \widetilde{\bm F}^{-1} \widetilde{\bm A}_{\bm d}
\widetilde{\bm F}$, from which we get $\bm{A_d}^H \bm{A_d} = \widetilde{\bm
F}^{-1} \widetilde{\bm A}_{\bm d}^H \widetilde{\bm A}_{\bm d} \widetilde{\bm
F}$. Applying the same procedure, we get $\bm \Sigma_x^{-1} =
\widetilde{\bm F}^{-1} \widetilde{\bm \Sigma}_x^{-1} \widetilde{\bm F}$.
The SSE cost for a measurement configuration $\bm d$ then becomes (scaling both terms
with $\lambda$):
\begin{align}
\text{Cost}(\bm{d}) & = tr\left(\left( {\bm A}_{\bm d}^H {\bm A}_{\bm d} +
\lambda \bm \Sigma_x^{-1} \right)^{-1} \right)
\label{eq:naive_cost}\\
% & = tr\left(\left(\widetilde{\bm F}^{-1} \widetilde{\bm
% A}_{\bm d}^H \widetilde{\bm A}_{\bm d} \widetilde{\bm F} + \lambda \widetilde{\bm
% F}^{-1} \widetilde{\bm D}^H \widetilde{\bm D} \widetilde{\bm
% F}\right)^{-1}\right) \nonumber \\
& = tr\left(\left(\widetilde{\bm F}^{-1} \left( \widetilde{\bm A}_{\bm d}^H
\widetilde{\bm A}_{\bm d} + \lambda \widetilde{\bm \Sigma}_x^{-1} \right)
\widetilde{\bm F}\right)^{-1}\right) \nonumber \\
& = tr\left(\widetilde{\bm F}^{-1} \left( \widetilde{\bm A}_{\bm d}^H
\widetilde{\bm A}_{\bm d} + \lambda \widetilde{\bm \Sigma}_x^{-1} \right)^{-1}
\widetilde{\bm F}\right) \nonumber \\
& = tr\left(\left( \widetilde{\bm A}_{\bm d}^H \widetilde{\bm A}_{\bm d} +
\lambda \widetilde{\bm \Sigma}_x^{-1} \right)^{-1} \right)
\label{eq:fast_cost}
\end{align}
where the computational complexity of \eqref{eq:fast_cost} is much less than
\eqref{eq:naive_cost} as both the multiplication and the inversion complexity
reduces significantly due to the diagonalized blocks.

\section{Complexity Analysis}

In this section, we derive the computational complexity of the standard, naive
SBS implementation and our faster version as a function of the number of pixels
in an image $N^2$, the number of spectral components $S$ in the source, and the
number of candidate measurement locations $C$.

\subsection{Complexity of Naive Implementation}

The computational complexity of evaluating cost for a particular measurement
configuration $\bm{d}$ comes from two places in the cost formulation.

$$
  \text{Cost}(\bm{d}) = \text{tr} \Bigl(
  \overbrace{\vphantom{\rule[1.5em]{0pt}{0pt}}
(\underbrace{\vphantom{\rule[-0.5em]{0pt}{0pt}} \bm{A}_{\bm{d}}^H \bm{A}_{\bm{d}}}_{O_m}
+\lambda \bm{D}^H\bm{D})^{-1}
}^{O_i}
\Bigr)
$$

The first contributor to cost complexity is the multiplication of
$\bm{A}^H_{\bm{d}}\bm{A}_{\bm{d}}$.  We can use a simple trick to avoid
multiplying the large $\bm{A}_{\bm{d}}$ in each iteration.

$$
\bm{A}^H_{\bm{d}} \bm{A}_{\bm{d}} = \sum_{d \in \bm{d}} \bm{A}^H_{d} \bm{A}_{d}
$$

With this property, we can simply precompute all $\bm{A}^H_{d}\bm{A}_{d}$ during
algorithm initialization and use the results to form
$\bm{A}^H_{\bm{d}}\bm{A}_{\bm{d}}$ as needed.
Since each $\bm{A}_d$ has shape $(1 \times SN^2)$, the overall complexity for precomputing $\bm{A}^H_d \bm{A}_d$ for all $C$ candidate locations is

$$
O_m = C \cdot O((SN^2)^2) = O(S^2N^4C)
$$

The second contributor to cost complexity is inversion of $\bm{A}^H_{\bm{d}}
\bm{A}_{\bm{d}} + \lambda\bm{D}^H \bm{D}$.
As $\bm{A}^H_{\bm{d}} \bm{A}_{\bm{d}}$ and $\bm{D}^H \bm{D}$ have dimension $(SN^2
\times SN^2)$, the complexity of inversion $O_i$ is given by

$$O_i = O\big( (SN^2)^3 \big) = O(S^3N^6)$$

The total complexity of the SBS algorithm can be written

\begin{align*}
  O_{sbs} &= O_m + \sum_{|\bm{d}| = M}^C |\bm{d}| O_i =
  \underbrace{
  O(S^2N^4C)
  }_{\substack{\text{multiplication}\\ \text{complexity}}}
  +
  \underbrace{
  O(S^3N^6C^2)
  }_{\substack{\text{inversion}\\ \text{complexity}}} \\
  &= O(S^3N^6C^2)
\end{align*}

% \begin{align*}
%   O_{sbs} = O_m + \sum_{|\bm{d}| = M}^C |\bm{d}| O_i =
%             \underbrace{
%             O(S^2N^4C)
%             }_{\substack{\text{multiplication}\\ \text{complexity}}} +
%             \underbrace{
%             O(S^3N^6C^2)
%             }_{\substack{\text{inversion}\\ \text{complexity}}}
% \end{align*}

% \begin{align*}
%   O_{sbs} &= \sum_{|\bm{d}| = M}^C |\bm{d}| \Big( O_m(|\bm{d}|) + O_i \Big) \\
%   &= \sum_{|\bm{d}| = M}^C O(S^2N^6|\bm{d}|^2) + \sum_{|\bm{d}| = M}^C O(S^3N^6|\bm{d}|) \\
%   &= \underbrace{O(S^2N^6C^3)}_{\text{multiplication complexity}} + \underbrace{O(S^3N^6C^2)}_{\text{inversion complexity}}
% \end{align*}
% \begin{align*}
%   O_{sbs} &= \sum_{|\bm{d}| = M}^C |\bm{d}| \Big( O_m(|\bm{d}|) + O_i \Big) \\
%   &= O(S^2N^6) \sum_{|\bm{d}| = M}^C O(|\bm{d}|^2) + O(S^3N^6) \sum_{|\bm{d}| = M}^C O(|\bm{d}|) \\
%   &= \underbrace{O(S^2N^6C^3)}_{\text{multiplication complexity}} + \underbrace{O(S^3N^6C^2)}_{\text{inversion complexity}}
% \end{align*}

\subsection{Complexity of Fast Implementation}

$$
\text{Cost}(\bm{d}) = tr\left(\left(
\widetilde{\bm A}_{\bm d}^H \widetilde{\bm A}_{\bm d} + \lambda \widetilde{\bm D}^H
\widetilde{\bm D} \right)^{-1} \right)
$$

In our fast SBS implementation, we use an alternative cost metric where the
diagonal blocks of $\widetilde{\bm{A}}_{\bm{d}}$ and $\widetilde{\bm{D}}$ greatly
  reduce the computational complexity of multiplication and inversion.

Since each $\bm{A}_d$ has shape $(1 \times S)$ with diagonal blocks of size $N^2$, the overall complexity for
precomputing $\bm{A}^H_d \bm{A}_d$ for all $C$ candidate locations is

$$
O_m = C \cdot O(S^2N^2) = O(S^2N^2C)
$$

A similar property can be exploited for accelerated inversion of BCCB blocks. \cite{kamaci2017}

$$
O_i = O(S^3N^2)
$$

Computing the total complexity of the SBS algorithm, we find that we obtain a
speedup of $N^4$, which is significant for large images.

\begin{align*}
  O_{sbs} &= O_m + \sum_{|\bm{d}| = M}^C |\bm{d}| O_i =
  \underbrace{
  O(S^2N^2C)
  }_{\substack{\text{multiplication}\\ \text{complexity}}}
  +
  \underbrace{
  O(S^3N^2C^2)
  }_{\substack{\text{inversion}\\ \text{complexity}}} \\
  &= O(S^3N^2C^2)
\end{align*}
% \begin{align*}
%   O_{sbs} &= O_m + \sum_{|\bm{d}| = M}^C |\bm{d}| O_i = O(S^2N^2C) + \sum_{|\bm{d}| = M}^C O(S^3N^2|\bm{d}|) \\
%   &= \underbrace{O(S^2N^2C)}_{\text{multiplication complexity}} + \underbrace{O(S^3N^2C^2)}_{\text{inversion complexity}}
% \end{align*}

\section{Numerical Experiments}
In this section, we present numerical results for reconstructing a simulated
$N^2{=}160^2$ polychromatic source with $S=2$ spectral components at $\lambda_1 =
\SI{33.400}{\nano\metre}$ and $\lambda_2 = \SI{33.402}{\nano\metre}$, shown as
separate colors in Figure \ref{fig:results}(a). In this experiment, we
initialized SBS with 12 repeated measurements at 32 candidate planes for a total
of $C = 384$ candidate measurements. We allowed SBS to run until only $M = 12$
measurements remain and show the final measurement configuration selected in
Figure \ref{fig:results}(d).  This plot shows that SBS has selected a set of
measurement locations outside the focal planes for the two spectral components,
marked with red and green bars. It took 1.68 seconds to run SBS on a computer
with an Intel Core i7 processor and 16GB RAM.

Figures \ref{fig:results}(e) and \ref{fig:results}(f) show the spectral
component reconstructions after disentangling and deblurring using Tikhonov
regularization. For comparison, we have included reconstructions yielded by
making an equal number of measurements at the focal planes of $\lambda_1$ and
$\lambda_2$ without applying SBS, shown in Figures \ref{fig:results}(b) and
\ref{fig:results}(c).  As compared to the reconstructions obtained from the SBS
measurements, the focal plane reconstructions are relatively noisier and exhibit
bleeding-over, where features appear in the wrong reconstruction.  This is
especially evident in Figure \ref{fig:results}(c).

\begin{figure}[t]
\begin{minipage}[b]{0.32\linewidth}
  \centering
  \centerline{\includegraphics[width=2.5cm]{sources}}
  \centerline{(a)}
\end{minipage}
\begin{minipage}[b]{0.32\linewidth}
  \centering
  \centerline{\includegraphics[width=2.5cm]{recon_focus1}}
  \centerline{(b)}
\end{minipage}
\begin{minipage}[b]{0.32\linewidth}
  \centering
  \centerline{\includegraphics[width=2.5cm]{recon_focus2}}
  \centerline{(c)}
\end{minipage}

\begin{minipage}[b]{0.32\linewidth}
  \centering
  \centerline{\includegraphics[width=3.6cm]{csbs_copies}}
  \centerline{(d)}
\end{minipage}
\begin{minipage}[b]{0.32\linewidth}
  \centering
  \centerline{\includegraphics[width=2.5cm]{recon_csbs1}}
  \centerline{(e)}
\end{minipage}
\begin{minipage}[b]{0.32\linewidth}
  \centering
  \centerline{\includegraphics[width=2.5cm]{recon_csbs2}}
  \centerline{(f)}
\end{minipage}
\caption{(a) polychromatic source image with spectral components $\lambda_1$ and
  $\lambda_2$ (b) reconstruction of $\lambda_1$ from focal configuration (c)
  reconstruction of $\lambda_2$ from focal configuration (d) measurement
  locations selected by SBS (e) reconstruction of
  $\lambda_1$ from SBS configuration (f) reconstruction of $\lambda_2$ from
  SBS configuration}
\label{fig:results}
\end{figure}

% Figure \ref{fig:results}d shows the reconstructed image of the wavelength
% $\lambda_1$ with the 12 CSBS planes given in Figure \ref{fig:results}f and
% Figure \ref{fig:results}e shows the same with using 6 measurements in each focal
% plane. As can be seen from Figure \ref{fig:results} and Table \ref{tab:ssims},
% CSBS planes lead to better reconstruction than the focal planes. The reason why
% CSBS avoids focal planes is that the relative contribution from the off focus
% line are quite high at focal planes which degrades the reconstruction quality
% as the deconvolution cannot disentangle the spectral lines well.

Finally, in Table \ref{tab:ssims}, we evaluate error in the reconstructed
spectral images using structural similary (SSIM) and peak signal-to-noise ratio
(PSNR), where the SBS reconstruction yielded better results measured by both metrics.

\vspace{-0.15 in}
\begin{table}[h]
\caption{SSIM/PSNR comparison for SBS vs focal planes}
\vspace{0.08 in}
\centering
\begin{tabular}{|c|c|c|}
\hline
      & Avg. SSIM  & Avg. PSNR  \\ \hline
Focal & 0.666 & 22.93 dB \\ \hline
SBS  & 0.764 & 26.56 dB \\ \hline
\end{tabular}
\label{tab:ssims}
\end{table}
\vspace{-0.15 in}

\section{Conclusion}

We apply a variant of the sequential backward selection algorithm to the problem
of acquisition in a diffractive spectral imaging system.  The high
dimensionality of large images makes a direct application of SBS and SSE cost
computationally intractable, so we have developed a more feasible implementation
of this algorithm and perform an analysis of its complexity to show that it is
significantly faster than the previous implementation for large images.
Finally, we demonstrate SBS on a simulated spectral imaging system and show that
the optimized measurement configuration achieves better reconstructions than a
naive choice of measurements at the spectral component focal planes.

\vfill\pagebreak

% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
\bibliographystyle{IEEEbib}
\bibliography{bibliography}

\end{document}
